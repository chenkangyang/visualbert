Using 8 workers out of 40 possible
{'batch_size': 64, 'num_gpus': 1, 'num_workers': 8}
Successfully loaded: bert.bert.embeddings.word_embeddings.weight
Successfully loaded: bert.bert.embeddings.position_embeddings.weight
Successfully loaded: bert.bert.embeddings.token_type_embeddings.weight
Successfully loaded: bert.bert.embeddings.LayerNorm.weight
Successfully loaded: bert.bert.embeddings.LayerNorm.bias
Successfully loaded: bert.bert.embeddings.token_type_embeddings_visual.weight
Successfully loaded: bert.bert.embeddings.position_embeddings_visual.weight
Successfully loaded: bert.bert.embeddings.projection.weight
Successfully loaded: bert.bert.embeddings.projection.bias
Successfully loaded: bert.bert.encoder.layer.0.attention.self.query.weight
Successfully loaded: bert.bert.encoder.layer.0.attention.self.query.bias
Successfully loaded: bert.bert.encoder.layer.0.attention.self.key.weight
Successfully loaded: bert.bert.encoder.layer.0.attention.self.key.bias
Successfully loaded: bert.bert.encoder.layer.0.attention.self.value.weight
Successfully loaded: bert.bert.encoder.layer.0.attention.self.value.bias
Successfully loaded: bert.bert.encoder.layer.0.attention.output.dense.weight
Successfully loaded: bert.bert.encoder.layer.0.attention.output.dense.bias
Successfully loaded: bert.bert.encoder.layer.0.attention.output.LayerNorm.weight
Successfully loaded: bert.bert.encoder.layer.0.attention.output.LayerNorm.bias
Successfully loaded: bert.bert.encoder.layer.0.intermediate.dense.weight
Successfully loaded: bert.bert.encoder.layer.0.intermediate.dense.bias
Successfully loaded: bert.bert.encoder.layer.0.output.dense.weight
Successfully loaded: bert.bert.encoder.layer.0.output.dense.bias
Successfully loaded: bert.bert.encoder.layer.0.output.LayerNorm.weight
Successfully loaded: bert.bert.encoder.layer.0.output.LayerNorm.bias
Successfully loaded: bert.bert.encoder.layer.1.attention.self.query.weight
Successfully loaded: bert.bert.encoder.layer.1.attention.self.query.bias
Successfully loaded: bert.bert.encoder.layer.1.attention.self.key.weight
Successfully loaded: bert.bert.encoder.layer.1.attention.self.key.bias
Successfully loaded: bert.bert.encoder.layer.1.attention.self.value.weight
Successfully loaded: bert.bert.encoder.layer.1.attention.self.value.bias
Successfully loaded: bert.bert.encoder.layer.1.attention.output.dense.weight
Successfully loaded: bert.bert.encoder.layer.1.attention.output.dense.bias
Successfully loaded: bert.bert.encoder.layer.1.attention.output.LayerNorm.weight
Successfully loaded: bert.bert.encoder.layer.1.attention.output.LayerNorm.bias
Successfully loaded: bert.bert.encoder.layer.1.intermediate.dense.weight
Successfully loaded: bert.bert.encoder.layer.1.intermediate.dense.bias
Successfully loaded: bert.bert.encoder.layer.1.output.dense.weight
Successfully loaded: bert.bert.encoder.layer.1.output.dense.bias
Successfully loaded: bert.bert.encoder.layer.1.output.LayerNorm.weight
Successfully loaded: bert.bert.encoder.layer.1.output.LayerNorm.bias
Successfully loaded: bert.bert.encoder.layer.2.attention.self.query.weight
Successfully loaded: bert.bert.encoder.layer.2.attention.self.query.bias
Successfully loaded: bert.bert.encoder.layer.2.attention.self.key.weight
Successfully loaded: bert.bert.encoder.layer.2.attention.self.key.bias
Successfully loaded: bert.bert.encoder.layer.2.attention.self.value.weight
Successfully loaded: bert.bert.encoder.layer.2.attention.self.value.bias
Successfully loaded: bert.bert.encoder.layer.2.attention.output.dense.weight
Successfully loaded: bert.bert.encoder.layer.2.attention.output.dense.bias
Successfully loaded: bert.bert.encoder.layer.2.attention.output.LayerNorm.weight
Successfully loaded: bert.bert.encoder.layer.2.attention.output.LayerNorm.bias
Successfully loaded: bert.bert.encoder.layer.2.intermediate.dense.weight
Successfully loaded: bert.bert.encoder.layer.2.intermediate.dense.bias
Successfully loaded: bert.bert.encoder.layer.2.output.dense.weight
Successfully loaded: bert.bert.encoder.layer.2.output.dense.bias
Successfully loaded: bert.bert.encoder.layer.2.output.LayerNorm.weight
Successfully loaded: bert.bert.encoder.layer.2.output.LayerNorm.bias
Successfully loaded: bert.bert.encoder.layer.3.attention.self.query.weight
Successfully loaded: bert.bert.encoder.layer.3.attention.self.query.bias
Successfully loaded: bert.bert.encoder.layer.3.attention.self.key.weight
Successfully loaded: bert.bert.encoder.layer.3.attention.self.key.bias
Successfully loaded: bert.bert.encoder.layer.3.attention.self.value.weight
Successfully loaded: bert.bert.encoder.layer.3.attention.self.value.bias
Successfully loaded: bert.bert.encoder.layer.3.attention.output.dense.weight
Successfully loaded: bert.bert.encoder.layer.3.attention.output.dense.bias
Successfully loaded: bert.bert.encoder.layer.3.attention.output.LayerNorm.weight
Successfully loaded: bert.bert.encoder.layer.3.attention.output.LayerNorm.bias
Successfully loaded: bert.bert.encoder.layer.3.intermediate.dense.weight
Successfully loaded: bert.bert.encoder.layer.3.intermediate.dense.bias
Successfully loaded: bert.bert.encoder.layer.3.output.dense.weight
Successfully loaded: bert.bert.encoder.layer.3.output.dense.bias
Successfully loaded: bert.bert.encoder.layer.3.output.LayerNorm.weight
Successfully loaded: bert.bert.encoder.layer.3.output.LayerNorm.bias
Successfully loaded: bert.bert.encoder.layer.4.attention.self.query.weight
Successfully loaded: bert.bert.encoder.layer.4.attention.self.query.bias
Successfully loaded: bert.bert.encoder.layer.4.attention.self.key.weight
Successfully loaded: bert.bert.encoder.layer.4.attention.self.key.bias
Successfully loaded: bert.bert.encoder.layer.4.attention.self.value.weight
Successfully loaded: bert.bert.encoder.layer.4.attention.self.value.bias
Successfully loaded: bert.bert.encoder.layer.4.attention.output.dense.weight
Successfully loaded: bert.bert.encoder.layer.4.attention.output.dense.bias
Successfully loaded: bert.bert.encoder.layer.4.attention.output.LayerNorm.weight
Successfully loaded: bert.bert.encoder.layer.4.attention.output.LayerNorm.bias
Successfully loaded: bert.bert.encoder.layer.4.intermediate.dense.weight
Successfully loaded: bert.bert.encoder.layer.4.intermediate.dense.bias
Successfully loaded: bert.bert.encoder.layer.4.output.dense.weight
Successfully loaded: bert.bert.encoder.layer.4.output.dense.bias
Successfully loaded: bert.bert.encoder.layer.4.output.LayerNorm.weight
Successfully loaded: bert.bert.encoder.layer.4.output.LayerNorm.bias
Successfully loaded: bert.bert.encoder.layer.5.attention.self.query.weight
Successfully loaded: bert.bert.encoder.layer.5.attention.self.query.bias
Successfully loaded: bert.bert.encoder.layer.5.attention.self.key.weight
Successfully loaded: bert.bert.encoder.layer.5.attention.self.key.bias
Successfully loaded: bert.bert.encoder.layer.5.attention.self.value.weight
Successfully loaded: bert.bert.encoder.layer.5.attention.self.value.bias
Successfully loaded: bert.bert.encoder.layer.5.attention.output.dense.weight
Successfully loaded: bert.bert.encoder.layer.5.attention.output.dense.bias
Successfully loaded: bert.bert.encoder.layer.5.attention.output.LayerNorm.weight
Successfully loaded: bert.bert.encoder.layer.5.attention.output.LayerNorm.bias
Successfully loaded: bert.bert.encoder.layer.5.intermediate.dense.weight
Successfully loaded: bert.bert.encoder.layer.5.intermediate.dense.bias
Successfully loaded: bert.bert.encoder.layer.5.output.dense.weight
Successfully loaded: bert.bert.encoder.layer.5.output.dense.bias
Successfully loaded: bert.bert.encoder.layer.5.output.LayerNorm.weight
Successfully loaded: bert.bert.encoder.layer.5.output.LayerNorm.bias
Successfully loaded: bert.bert.encoder.layer.6.attention.self.query.weight
Successfully loaded: bert.bert.encoder.layer.6.attention.self.query.bias
Successfully loaded: bert.bert.encoder.layer.6.attention.self.key.weight
Successfully loaded: bert.bert.encoder.layer.6.attention.self.key.bias
Successfully loaded: bert.bert.encoder.layer.6.attention.self.value.weight
Successfully loaded: bert.bert.encoder.layer.6.attention.self.value.bias
Successfully loaded: bert.bert.encoder.layer.6.attention.output.dense.weight
Successfully loaded: bert.bert.encoder.layer.6.attention.output.dense.bias
Successfully loaded: bert.bert.encoder.layer.6.attention.output.LayerNorm.weight
Successfully loaded: bert.bert.encoder.layer.6.attention.output.LayerNorm.bias
Successfully loaded: bert.bert.encoder.layer.6.intermediate.dense.weight
Successfully loaded: bert.bert.encoder.layer.6.intermediate.dense.bias
Successfully loaded: bert.bert.encoder.layer.6.output.dense.weight
Successfully loaded: bert.bert.encoder.layer.6.output.dense.bias
Successfully loaded: bert.bert.encoder.layer.6.output.LayerNorm.weight
Successfully loaded: bert.bert.encoder.layer.6.output.LayerNorm.bias
Successfully loaded: bert.bert.encoder.layer.7.attention.self.query.weight
Successfully loaded: bert.bert.encoder.layer.7.attention.self.query.bias
Successfully loaded: bert.bert.encoder.layer.7.attention.self.key.weight
Successfully loaded: bert.bert.encoder.layer.7.attention.self.key.bias
Successfully loaded: bert.bert.encoder.layer.7.attention.self.value.weight
Successfully loaded: bert.bert.encoder.layer.7.attention.self.value.bias
Successfully loaded: bert.bert.encoder.layer.7.attention.output.dense.weight
Successfully loaded: bert.bert.encoder.layer.7.attention.output.dense.bias
Successfully loaded: bert.bert.encoder.layer.7.attention.output.LayerNorm.weight
Successfully loaded: bert.bert.encoder.layer.7.attention.output.LayerNorm.bias
Successfully loaded: bert.bert.encoder.layer.7.intermediate.dense.weight
Successfully loaded: bert.bert.encoder.layer.7.intermediate.dense.bias
Successfully loaded: bert.bert.encoder.layer.7.output.dense.weight
Successfully loaded: bert.bert.encoder.layer.7.output.dense.bias
Successfully loaded: bert.bert.encoder.layer.7.output.LayerNorm.weight
Successfully loaded: bert.bert.encoder.layer.7.output.LayerNorm.bias
Successfully loaded: bert.bert.encoder.layer.8.attention.self.query.weight
Successfully loaded: bert.bert.encoder.layer.8.attention.self.query.bias
Successfully loaded: bert.bert.encoder.layer.8.attention.self.key.weight
Successfully loaded: bert.bert.encoder.layer.8.attention.self.key.bias
Successfully loaded: bert.bert.encoder.layer.8.attention.self.value.weight
Successfully loaded: bert.bert.encoder.layer.8.attention.self.value.bias
Successfully loaded: bert.bert.encoder.layer.8.attention.output.dense.weight
Successfully loaded: bert.bert.encoder.layer.8.attention.output.dense.bias
Successfully loaded: bert.bert.encoder.layer.8.attention.output.LayerNorm.weight
Successfully loaded: bert.bert.encoder.layer.8.attention.output.LayerNorm.bias
Successfully loaded: bert.bert.encoder.layer.8.intermediate.dense.weight
Successfully loaded: bert.bert.encoder.layer.8.intermediate.dense.bias
Successfully loaded: bert.bert.encoder.layer.8.output.dense.weight
Successfully loaded: bert.bert.encoder.layer.8.output.dense.bias
Successfully loaded: bert.bert.encoder.layer.8.output.LayerNorm.weight
Successfully loaded: bert.bert.encoder.layer.8.output.LayerNorm.bias
Successfully loaded: bert.bert.encoder.layer.9.attention.self.query.weight
Successfully loaded: bert.bert.encoder.layer.9.attention.self.query.bias
Successfully loaded: bert.bert.encoder.layer.9.attention.self.key.weight
Successfully loaded: bert.bert.encoder.layer.9.attention.self.key.bias
Successfully loaded: bert.bert.encoder.layer.9.attention.self.value.weight
Successfully loaded: bert.bert.encoder.layer.9.attention.self.value.bias
Successfully loaded: bert.bert.encoder.layer.9.attention.output.dense.weight
Successfully loaded: bert.bert.encoder.layer.9.attention.output.dense.bias
Successfully loaded: bert.bert.encoder.layer.9.attention.output.LayerNorm.weight
Successfully loaded: bert.bert.encoder.layer.9.attention.output.LayerNorm.bias
Successfully loaded: bert.bert.encoder.layer.9.intermediate.dense.weight
Successfully loaded: bert.bert.encoder.layer.9.intermediate.dense.bias
Successfully loaded: bert.bert.encoder.layer.9.output.dense.weight
Successfully loaded: bert.bert.encoder.layer.9.output.dense.bias
Successfully loaded: bert.bert.encoder.layer.9.output.LayerNorm.weight
Successfully loaded: bert.bert.encoder.layer.9.output.LayerNorm.bias
Successfully loaded: bert.bert.encoder.layer.10.attention.self.query.weight
Successfully loaded: bert.bert.encoder.layer.10.attention.self.query.bias
Successfully loaded: bert.bert.encoder.layer.10.attention.self.key.weight
Successfully loaded: bert.bert.encoder.layer.10.attention.self.key.bias
Successfully loaded: bert.bert.encoder.layer.10.attention.self.value.weight
Successfully loaded: bert.bert.encoder.layer.10.attention.self.value.bias
Successfully loaded: bert.bert.encoder.layer.10.attention.output.dense.weight
Successfully loaded: bert.bert.encoder.layer.10.attention.output.dense.bias
Successfully loaded: bert.bert.encoder.layer.10.attention.output.LayerNorm.weight
Successfully loaded: bert.bert.encoder.layer.10.attention.output.LayerNorm.bias
Successfully loaded: bert.bert.encoder.layer.10.intermediate.dense.weight
Successfully loaded: bert.bert.encoder.layer.10.intermediate.dense.bias
Successfully loaded: bert.bert.encoder.layer.10.output.dense.weight
Successfully loaded: bert.bert.encoder.layer.10.output.dense.bias
Successfully loaded: bert.bert.encoder.layer.10.output.LayerNorm.weight
Successfully loaded: bert.bert.encoder.layer.10.output.LayerNorm.bias
Successfully loaded: bert.bert.encoder.layer.11.attention.self.query.weight
Successfully loaded: bert.bert.encoder.layer.11.attention.self.query.bias
Successfully loaded: bert.bert.encoder.layer.11.attention.self.key.weight
Successfully loaded: bert.bert.encoder.layer.11.attention.self.key.bias
Successfully loaded: bert.bert.encoder.layer.11.attention.self.value.weight
Successfully loaded: bert.bert.encoder.layer.11.attention.self.value.bias
Successfully loaded: bert.bert.encoder.layer.11.attention.output.dense.weight
Successfully loaded: bert.bert.encoder.layer.11.attention.output.dense.bias
Successfully loaded: bert.bert.encoder.layer.11.attention.output.LayerNorm.weight
Successfully loaded: bert.bert.encoder.layer.11.attention.output.LayerNorm.bias
Successfully loaded: bert.bert.encoder.layer.11.intermediate.dense.weight
Successfully loaded: bert.bert.encoder.layer.11.intermediate.dense.bias
Successfully loaded: bert.bert.encoder.layer.11.output.dense.weight
Successfully loaded: bert.bert.encoder.layer.11.output.dense.bias
Successfully loaded: bert.bert.encoder.layer.11.output.LayerNorm.weight
Successfully loaded: bert.bert.encoder.layer.11.output.LayerNorm.bias
Successfully loaded: bert.bert.pooler.dense.weight
Successfully loaded: bert.bert.pooler.dense.bias
Successfully loaded: bert.classifier.weight
Successfully loaded: bert.classifier.bias
No detector found.

 113.9M total parameters. 113.9M training 
 ----- 
                                                                            shape      size  requires_grad
name                                                                                                     
module.bert.bert.embeddings.word_embeddings.weight                   [30522,768]  23440896           True
module.bert.classifier.weight                                         [3129,768]   2403072           True
module.bert.bert.encoder.layer.0.intermediate.dense.weight            [3072,768]   2359296           True
module.bert.bert.encoder.layer.0.output.dense.weight                  [768,3072]   2359296           True
module.bert.bert.encoder.layer.1.intermediate.dense.weight            [3072,768]   2359296           True
module.bert.bert.encoder.layer.1.output.dense.weight                  [768,3072]   2359296           True
module.bert.bert.encoder.layer.2.intermediate.dense.weight            [3072,768]   2359296           True
module.bert.bert.encoder.layer.2.output.dense.weight                  [768,3072]   2359296           True
module.bert.bert.encoder.layer.3.intermediate.dense.weight            [3072,768]   2359296           True
module.bert.bert.encoder.layer.3.output.dense.weight                  [768,3072]   2359296           True
module.bert.bert.encoder.layer.4.intermediate.dense.weight            [3072,768]   2359296           True
module.bert.bert.encoder.layer.4.output.dense.weight                  [768,3072]   2359296           True
module.bert.bert.encoder.layer.5.intermediate.dense.weight            [3072,768]   2359296           True
module.bert.bert.encoder.layer.5.output.dense.weight                  [768,3072]   2359296           True
module.bert.bert.encoder.layer.6.intermediate.dense.weight            [3072,768]   2359296           True
module.bert.bert.encoder.layer.6.output.dense.weight                  [768,3072]   2359296           True
module.bert.bert.encoder.layer.7.intermediate.dense.weight            [3072,768]   2359296           True
module.bert.bert.encoder.layer.7.output.dense.weight                  [768,3072]   2359296           True
module.bert.bert.encoder.layer.8.intermediate.dense.weight            [3072,768]   2359296           True
module.bert.bert.encoder.layer.8.output.dense.weight                  [768,3072]   2359296           True
module.bert.bert.encoder.layer.9.intermediate.dense.weight            [3072,768]   2359296           True
module.bert.bert.encoder.layer.9.output.dense.weight                  [768,3072]   2359296           True
module.bert.bert.encoder.layer.10.intermediate.dense.weight           [3072,768]   2359296           True
module.bert.bert.encoder.layer.10.output.dense.weight                 [768,3072]   2359296           True
module.bert.bert.encoder.layer.11.intermediate.dense.weight           [3072,768]   2359296           True
module.bert.bert.encoder.layer.11.output.dense.weight                 [768,3072]   2359296           True
module.bert.bert.embeddings.projection.weight                         [768,2048]   1572864           True
module.bert.bert.encoder.layer.0.attention.self.query.weight           [768,768]    589824           True
module.bert.bert.encoder.layer.0.attention.self.key.weight             [768,768]    589824           True
module.bert.bert.encoder.layer.0.attention.self.value.weight           [768,768]    589824           True
module.bert.bert.encoder.layer.0.attention.output.dense.weight         [768,768]    589824           True
module.bert.bert.encoder.layer.1.attention.self.query.weight           [768,768]    589824           True
module.bert.bert.encoder.layer.1.attention.self.key.weight             [768,768]    589824           True
module.bert.bert.encoder.layer.1.attention.self.value.weight           [768,768]    589824           True
module.bert.bert.encoder.layer.1.attention.output.dense.weight         [768,768]    589824           True
module.bert.bert.encoder.layer.2.attention.self.query.weight           [768,768]    589824           True
module.bert.bert.encoder.layer.2.attention.self.key.weight             [768,768]    589824           True
module.bert.bert.encoder.layer.2.attention.self.value.weight           [768,768]    589824           True
module.bert.bert.encoder.layer.2.attention.output.dense.weight         [768,768]    589824           True
module.bert.bert.encoder.layer.3.attention.self.query.weight           [768,768]    589824           True
module.bert.bert.encoder.layer.3.attention.self.key.weight             [768,768]    589824           True
module.bert.bert.encoder.layer.3.attention.self.value.weight           [768,768]    589824           True
module.bert.bert.encoder.layer.3.attention.output.dense.weight         [768,768]    589824           True
module.bert.bert.encoder.layer.4.attention.self.query.weight           [768,768]    589824           True
module.bert.bert.encoder.layer.4.attention.self.key.weight             [768,768]    589824           True
module.bert.bert.encoder.layer.4.attention.self.value.weight           [768,768]    589824           True
module.bert.bert.encoder.layer.4.attention.output.dense.weight         [768,768]    589824           True
module.bert.bert.encoder.layer.5.attention.self.query.weight           [768,768]    589824           True
module.bert.bert.encoder.layer.5.attention.self.key.weight             [768,768]    589824           True
module.bert.bert.encoder.layer.5.attention.self.value.weight           [768,768]    589824           True
module.bert.bert.encoder.layer.5.attention.output.dense.weight         [768,768]    589824           True
module.bert.bert.encoder.layer.6.attention.self.query.weight           [768,768]    589824           True
module.bert.bert.encoder.layer.6.attention.self.key.weight             [768,768]    589824           True
module.bert.bert.encoder.layer.6.attention.self.value.weight           [768,768]    589824           True
module.bert.bert.encoder.layer.6.attention.output.dense.weight         [768,768]    589824           True
module.bert.bert.encoder.layer.7.attention.self.query.weight           [768,768]    589824           True
module.bert.bert.encoder.layer.7.attention.self.key.weight             [768,768]    589824           True
module.bert.bert.encoder.layer.7.attention.self.value.weight           [768,768]    589824           True
module.bert.bert.encoder.layer.7.attention.output.dense.weight         [768,768]    589824           True
module.bert.bert.encoder.layer.8.attention.self.query.weight           [768,768]    589824           True
module.bert.bert.encoder.layer.8.attention.self.key.weight             [768,768]    589824           True
module.bert.bert.encoder.layer.8.attention.self.value.weight           [768,768]    589824           True
module.bert.bert.encoder.layer.8.attention.output.dense.weight         [768,768]    589824           True
module.bert.bert.encoder.layer.9.attention.self.query.weight           [768,768]    589824           True
module.bert.bert.encoder.layer.9.attention.self.key.weight             [768,768]    589824           True
module.bert.bert.encoder.layer.9.attention.self.value.weight           [768,768]    589824           True
module.bert.bert.encoder.layer.9.attention.output.dense.weight         [768,768]    589824           True
module.bert.bert.encoder.layer.10.attention.self.query.weight          [768,768]    589824           True
module.bert.bert.encoder.layer.10.attention.self.key.weight            [768,768]    589824           True
module.bert.bert.encoder.layer.10.attention.self.value.weight          [768,768]    589824           True
module.bert.bert.encoder.layer.10.attention.output.dense.weight        [768,768]    589824           True
module.bert.bert.encoder.layer.11.attention.self.query.weight          [768,768]    589824           True
module.bert.bert.encoder.layer.11.attention.self.key.weight            [768,768]    589824           True
module.bert.bert.encoder.layer.11.attention.self.value.weight          [768,768]    589824           True
module.bert.bert.encoder.layer.11.attention.output.dense.weight        [768,768]    589824           True
module.bert.bert.pooler.dense.weight                                   [768,768]    589824           True
module.bert.bert.embeddings.position_embeddings.weight                 [512,768]    393216           True
module.bert.bert.embeddings.position_embeddings_visual.weight          [512,768]    393216           True
module.bert.classifier.bias                                               [3129]      3129           True
module.bert.bert.encoder.layer.0.intermediate.dense.bias                  [3072]      3072           True
module.bert.bert.encoder.layer.1.intermediate.dense.bias                  [3072]      3072           True
module.bert.bert.encoder.layer.2.intermediate.dense.bias                  [3072]      3072           True
module.bert.bert.encoder.layer.3.intermediate.dense.bias                  [3072]      3072           True
module.bert.bert.encoder.layer.4.intermediate.dense.bias                  [3072]      3072           True
module.bert.bert.encoder.layer.5.intermediate.dense.bias                  [3072]      3072           True
module.bert.bert.encoder.layer.6.intermediate.dense.bias                  [3072]      3072           True
module.bert.bert.encoder.layer.7.intermediate.dense.bias                  [3072]      3072           True
module.bert.bert.encoder.layer.8.intermediate.dense.bias                  [3072]      3072           True
module.bert.bert.encoder.layer.9.intermediate.dense.bias                  [3072]      3072           True
module.bert.bert.encoder.layer.10.intermediate.dense.bias                 [3072]      3072           True
module.bert.bert.encoder.layer.11.intermediate.dense.bias                 [3072]      3072           True
module.bert.bert.embeddings.token_type_embeddings.weight                 [2,768]      1536           True
module.bert.bert.embeddings.token_type_embeddings_visual.weight          [2,768]      1536           True
module.bert.bert.embeddings.LayerNorm.weight                               [768]       768           True
module.bert.bert.embeddings.LayerNorm.bias                                 [768]       768           True
module.bert.bert.embeddings.projection.bias                                [768]       768           True
module.bert.bert.encoder.layer.0.attention.self.query.bias                 [768]       768           True
module.bert.bert.encoder.layer.0.attention.self.key.bias                   [768]       768           True
module.bert.bert.encoder.layer.0.attention.self.value.bias                 [768]       768           True
module.bert.bert.encoder.layer.0.attention.output.dense.bias               [768]       768           True
module.bert.bert.encoder.layer.0.attention.output.LayerNorm.weight         [768]       768           True
module.bert.bert.encoder.layer.0.attention.output.LayerNorm.bias           [768]       768           True
module.bert.bert.encoder.layer.0.output.dense.bias                         [768]       768           True
module.bert.bert.encoder.layer.0.output.LayerNorm.weight                   [768]       768           True
module.bert.bert.encoder.layer.0.output.LayerNorm.bias                     [768]       768           True
module.bert.bert.encoder.layer.1.attention.self.query.bias                 [768]       768           True
module.bert.bert.encoder.layer.1.attention.self.key.bias                   [768]       768           True
module.bert.bert.encoder.layer.1.attention.self.value.bias                 [768]       768           True
module.bert.bert.encoder.layer.1.attention.output.dense.bias               [768]       768           True
module.bert.bert.encoder.layer.1.attention.output.LayerNorm.weight         [768]       768           True
module.bert.bert.encoder.layer.1.attention.output.LayerNorm.bias           [768]       768           True
module.bert.bert.encoder.layer.1.output.dense.bias                         [768]       768           True
module.bert.bert.encoder.layer.1.output.LayerNorm.weight                   [768]       768           True
module.bert.bert.encoder.layer.1.output.LayerNorm.bias                     [768]       768           True
module.bert.bert.encoder.layer.2.attention.self.query.bias                 [768]       768           True
module.bert.bert.encoder.layer.2.attention.self.key.bias                   [768]       768           True
module.bert.bert.encoder.layer.2.attention.self.value.bias                 [768]       768           True
module.bert.bert.encoder.layer.2.attention.output.dense.bias               [768]       768           True
module.bert.bert.encoder.layer.2.attention.output.LayerNorm.weight         [768]       768           True
module.bert.bert.encoder.layer.2.attention.output.LayerNorm.bias           [768]       768           True
module.bert.bert.encoder.layer.2.output.dense.bias                         [768]       768           True
module.bert.bert.encoder.layer.2.output.LayerNorm.weight                   [768]       768           True
module.bert.bert.encoder.layer.2.output.LayerNorm.bias                     [768]       768           True
module.bert.bert.encoder.layer.3.attention.self.query.bias                 [768]       768           True
module.bert.bert.encoder.layer.3.attention.self.key.bias                   [768]       768           True
module.bert.bert.encoder.layer.3.attention.self.value.bias                 [768]       768           True
module.bert.bert.encoder.layer.3.attention.output.dense.bias               [768]       768           True
module.bert.bert.encoder.layer.3.attention.output.LayerNorm.weight         [768]       768           True
module.bert.bert.encoder.layer.3.attention.output.LayerNorm.bias           [768]       768           True
module.bert.bert.encoder.layer.3.output.dense.bias                         [768]       768           True
module.bert.bert.encoder.layer.3.output.LayerNorm.weight                   [768]       768           True
module.bert.bert.encoder.layer.3.output.LayerNorm.bias                     [768]       768           True
module.bert.bert.encoder.layer.4.attention.self.query.bias                 [768]       768           True
module.bert.bert.encoder.layer.4.attention.self.key.bias                   [768]       768           True
module.bert.bert.encoder.layer.4.attention.self.value.bias                 [768]       768           True
module.bert.bert.encoder.layer.4.attention.output.dense.bias               [768]       768           True
module.bert.bert.encoder.layer.4.attention.output.LayerNorm.weight         [768]       768           True
module.bert.bert.encoder.layer.4.attention.output.LayerNorm.bias           [768]       768           True
module.bert.bert.encoder.layer.4.output.dense.bias                         [768]       768           True
module.bert.bert.encoder.layer.4.output.LayerNorm.weight                   [768]       768           True
module.bert.bert.encoder.layer.4.output.LayerNorm.bias                     [768]       768           True
module.bert.bert.encoder.layer.5.attention.self.query.bias                 [768]       768           True
module.bert.bert.encoder.layer.5.attention.self.key.bias                   [768]       768           True
module.bert.bert.encoder.layer.5.attention.self.value.bias                 [768]       768           True
module.bert.bert.encoder.layer.5.attention.output.dense.bias               [768]       768           True
module.bert.bert.encoder.layer.5.attention.output.LayerNorm.weight         [768]       768           True
module.bert.bert.encoder.layer.5.attention.output.LayerNorm.bias           [768]       768           True
module.bert.bert.encoder.layer.5.output.dense.bias                         [768]       768           True
module.bert.bert.encoder.layer.5.output.LayerNorm.weight                   [768]       768           True
module.bert.bert.encoder.layer.5.output.LayerNorm.bias                     [768]       768           True
module.bert.bert.encoder.layer.6.attention.self.query.bias                 [768]       768           True
module.bert.bert.encoder.layer.6.attention.self.key.bias                   [768]       768           True
module.bert.bert.encoder.layer.6.attention.self.value.bias                 [768]       768           True
module.bert.bert.encoder.layer.6.attention.output.dense.bias               [768]       768           True
module.bert.bert.encoder.layer.6.attention.output.LayerNorm.weight         [768]       768           True
module.bert.bert.encoder.layer.6.attention.output.LayerNorm.bias           [768]       768           True
module.bert.bert.encoder.layer.6.output.dense.bias                         [768]       768           True
module.bert.bert.encoder.layer.6.output.LayerNorm.weight                   [768]       768           True
module.bert.bert.encoder.layer.6.output.LayerNorm.bias                     [768]       768           True
module.bert.bert.encoder.layer.7.attention.self.query.bias                 [768]       768           True
module.bert.bert.encoder.layer.7.attention.self.key.bias                   [768]       768           True
module.bert.bert.encoder.layer.7.attention.self.value.bias                 [768]       768           True
module.bert.bert.encoder.layer.7.attention.output.dense.bias               [768]       768           True
module.bert.bert.encoder.layer.7.attention.output.LayerNorm.weight         [768]       768           True
module.bert.bert.encoder.layer.7.attention.output.LayerNorm.bias           [768]       768           True
module.bert.bert.encoder.layer.7.output.dense.bias                         [768]       768           True
module.bert.bert.encoder.layer.7.output.LayerNorm.weight                   [768]       768           True
module.bert.bert.encoder.layer.7.output.LayerNorm.bias                     [768]       768           True
module.bert.bert.encoder.layer.8.attention.self.query.bias                 [768]       768           True
module.bert.bert.encoder.layer.8.attention.self.key.bias                   [768]       768           True
module.bert.bert.encoder.layer.8.attention.self.value.bias                 [768]       768           True
module.bert.bert.encoder.layer.8.attention.output.dense.bias               [768]       768           True
module.bert.bert.encoder.layer.8.attention.output.LayerNorm.weight         [768]       768           True
module.bert.bert.encoder.layer.8.attention.output.LayerNorm.bias           [768]       768           True
module.bert.bert.encoder.layer.8.output.dense.bias                         [768]       768           True
module.bert.bert.encoder.layer.8.output.LayerNorm.weight                   [768]       768           True
module.bert.bert.encoder.layer.8.output.LayerNorm.bias                     [768]       768           True
module.bert.bert.encoder.layer.9.attention.self.query.bias                 [768]       768           True
module.bert.bert.encoder.layer.9.attention.self.key.bias                   [768]       768           True
module.bert.bert.encoder.layer.9.attention.self.value.bias                 [768]       768           True
module.bert.bert.encoder.layer.9.attention.output.dense.bias               [768]       768           True
module.bert.bert.encoder.layer.9.attention.output.LayerNorm.weight         [768]       768           True
module.bert.bert.encoder.layer.9.attention.output.LayerNorm.bias           [768]       768           True
module.bert.bert.encoder.layer.9.output.dense.bias                         [768]       768           True
module.bert.bert.encoder.layer.9.output.LayerNorm.weight                   [768]       768           True
module.bert.bert.encoder.layer.9.output.LayerNorm.bias                     [768]       768           True
module.bert.bert.encoder.layer.10.attention.self.query.bias                [768]       768           True
module.bert.bert.encoder.layer.10.attention.self.key.bias                  [768]       768           True
module.bert.bert.encoder.layer.10.attention.self.value.bias                [768]       768           True
module.bert.bert.encoder.layer.10.attention.output.dense.bias              [768]       768           True
module.bert.bert.encoder.layer.10.attention.output.LayerNorm.weight        [768]       768           True
module.bert.bert.encoder.layer.10.attention.output.LayerNorm.bias          [768]       768           True
module.bert.bert.encoder.layer.10.output.dense.bias                        [768]       768           True
module.bert.bert.encoder.layer.10.output.LayerNorm.weight                  [768]       768           True
module.bert.bert.encoder.layer.10.output.LayerNorm.bias                    [768]       768           True
module.bert.bert.encoder.layer.11.attention.self.query.bias                [768]       768           True
module.bert.bert.encoder.layer.11.attention.self.key.bias                  [768]       768           True
module.bert.bert.encoder.layer.11.attention.self.value.bias                [768]       768           True
module.bert.bert.encoder.layer.11.attention.output.dense.bias              [768]       768           True
module.bert.bert.encoder.layer.11.attention.output.LayerNorm.weight        [768]       768           True
module.bert.bert.encoder.layer.11.attention.output.LayerNorm.bias          [768]       768           True
module.bert.bert.encoder.layer.11.output.dense.bias                        [768]       768           True
module.bert.bert.encoder.layer.11.output.LayerNorm.weight                  [768]       768           True
module.bert.bert.encoder.layer.11.output.LayerNorm.bias                    [768]       768           True
module.bert.bert.pooler.dense.bias                                         [768]       768           True 
 ----
AttrDict({'dataset': 'vqa', 'data_root': 'X_COCO', 'use_visual_genome': True, 'max_seq_length': 128, 'bert_model_name': '/home/chenkangyang/workspace/visualbert/models/bert-base-uncased', 'do_lower_case': True, 'train_batch_size': 64, 'eval_batch_size': 64, 'do_test': True, 'skip_training': True, 'epoch_to_load': None, 'pretraining': False, 'no_next_sentence': True, 'patience': 3, 'learning_rate': 2e-05, 'num_train_epochs': 10, 'warmup_proportion': 0.1, 'grad_norm': 0.25, 'gradient_accumulation_steps': 1, 'restore_bin': '/home/chenkangyang/workspace/visualbert/models/uclanlp/vqa_fine_tuned.th', 'include_res152': False, 'num_workers': 8, 'val_workers': 2, 'model': {'type': 'VisualBERTFixedImageEmbedding', 'special_visual_initialize': True, 'training_head_type': 'vqa', 'visual_embedding_dim': 2048}, 'folder': 'logs/vqa_finetune_0831', 'no_tqdm': False, 'config': '/home/chenkangyang/workspace/visualbert/visualbert/configs/vqa/fine-tune.json', 'fp16': False})
########### Starting from 0
Finished testing
Something Went Wrong with Evaluation. Ignored.
